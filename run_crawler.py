#!/usr/bin/env python3
"""
ì£¼ì‹ ê¸°ìˆ  íŠ¸ë Œë“œ í¬ë¡¤ë§ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
"""

import os
import sys
import subprocess
from datetime import datetime
import argparse

def setup_environment():
    """í™˜ê²½ ì„¤ì •"""
    # config.env íŒŒì¼ì„ .envë¡œ ë³µì‚¬
    if os.path.exists('config.env') and not os.path.exists('.env'):
        with open('config.env', 'r', encoding='utf-8') as src:
            with open('.env', 'w', encoding='utf-8') as dst:
                dst.write(src.read())
        print("âœ… í™˜ê²½ ì„¤ì • íŒŒì¼ ìƒì„± ì™„ë£Œ")

def run_spider(spider_name, output_format='json'):
    """ìŠ¤íŒŒì´ë” ì‹¤í–‰"""
    print(f"ğŸš€ {spider_name} í¬ë¡¤ë§ ì‹œì‘...")
    
    # ì¶œë ¥ íŒŒì¼ëª… ìƒì„±
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = f"data/{spider_name}_{timestamp}.{output_format}"
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs('data', exist_ok=True)
    
    # Scrapy ëª…ë ¹ì–´ ì‹¤í–‰
    cmd = [
        'scrapy', 'crawl', spider_name,
        '-o', output_file,
        '--loglevel=INFO'
    ]
    
    try:
        result = subprocess.run(cmd, cwd='stock_tech_trends', check=True)
        print(f"âœ… {spider_name} í¬ë¡¤ë§ ì™„ë£Œ: {output_file}")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ {spider_name} í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
        return False

def run_all_spiders():
    """ëª¨ë“  ìŠ¤íŒŒì´ë” ì‹¤í–‰"""
    spiders = ['reddit_spider', 'hackernews_spider', 'github_spider']
    
    print("ğŸ¯ ëª¨ë“  ìŠ¤íŒŒì´ë” ì‹¤í–‰ ì‹œì‘...")
    
    results = []
    for spider in spiders:
        success = run_spider(spider)
        results.append((spider, success))
    
    # ê²°ê³¼ ìš”ì•½
    print("\nğŸ“Š í¬ë¡¤ë§ ê²°ê³¼ ìš”ì•½:")
    for spider, success in results:
        status = "âœ… ì„±ê³µ" if success else "âŒ ì‹¤íŒ¨"
        print(f"  {spider}: {status}")
    
    successful = sum(1 for _, success in results if success)
    print(f"\nì´ {len(results)}ê°œ ì¤‘ {successful}ê°œ ì„±ê³µ")

def main():
    parser = argparse.ArgumentParser(description='ì£¼ì‹ ê¸°ìˆ  íŠ¸ë Œë“œ í¬ë¡¤ë§ ì‹¤í–‰ê¸°')
    parser.add_argument('spider', nargs='?', help='ì‹¤í–‰í•  ìŠ¤íŒŒì´ë” ì´ë¦„ (ê¸°ë³¸ê°’: all)')
    parser.add_argument('--format', '-f', default='json', choices=['json', 'csv', 'xml'], 
                       help='ì¶œë ¥ í˜•ì‹ (ê¸°ë³¸ê°’: json)')
    
    args = parser.parse_args()
    
    # í™˜ê²½ ì„¤ì •
    setup_environment()
    
    if args.spider:
        # íŠ¹ì • ìŠ¤íŒŒì´ë” ì‹¤í–‰
        run_spider(args.spider, args.format)
    else:
        # ëª¨ë“  ìŠ¤íŒŒì´ë” ì‹¤í–‰
        run_all_spiders()

if __name__ == '__main__':
    main()
