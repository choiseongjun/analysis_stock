"""
ê³ ê¸‰ ê°ì„± ë¶„ì„ ëª¨ë“ˆ
"""

import re
import json
from typing import Dict, List, Tuple, Optional
from collections import Counter
import numpy as np
import pandas as pd
from datetime import datetime

# ê°ì„± ë¶„ì„ ë¼ì´ë¸ŒëŸ¬ë¦¬
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from textblob import TextBlob

# í•œêµ­ì–´ ê°ì„± ë¶„ì„ì„ ìœ„í•œ ì¶”ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì„ íƒì‚¬í•­)
try:
    from konlpy.tag import Okt
    KOREAN_SUPPORT = True
except ImportError:
    KOREAN_SUPPORT = False
    print("í•œêµ­ì–´ ì§€ì›ì„ ìœ„í•´ konlpyë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”: pip install konlpy")

# ì£¼ì‹/ê¸°ìˆ  ê´€ë ¨ ê°ì„± ì‚¬ì „
STOCK_SENTIMENT_DICT = {
    # ê¸ì •ì  í‚¤ì›Œë“œ
    'positive': [
        'bullish', 'growth', 'profit', 'gain', 'rise', 'increase', 'up', 'high',
        'success', 'breakthrough', 'innovation', 'advancement', 'improvement',
        'strong', 'robust', 'solid', 'excellent', 'outstanding', 'amazing',
        'buy', 'purchase', 'invest', 'opportunity', 'potential', 'promising',
        'earnings', 'revenue', 'dividend', 'return', 'yield', 'performance'
    ],
    # ë¶€ì •ì  í‚¤ì›Œë“œ
    'negative': [
        'bearish', 'decline', 'loss', 'fall', 'drop', 'decrease', 'down', 'low',
        'failure', 'problem', 'issue', 'concern', 'risk', 'threat', 'danger',
        'weak', 'poor', 'terrible', 'awful', 'disappointing', 'concerning',
        'sell', 'short', 'avoid', 'warning', 'caution', 'volatile', 'uncertain',
        'debt', 'loss', 'bankruptcy', 'crisis', 'recession', 'crash'
    ],
    # ê¸°ìˆ  ê´€ë ¨ í‚¤ì›Œë“œ
    'tech_positive': [
        'breakthrough', 'innovation', 'revolutionary', 'cutting-edge', 'advanced',
        'efficient', 'scalable', 'reliable', 'secure', 'fast', 'powerful',
        'ai', 'machine learning', 'automation', 'optimization', 'enhancement',
        'upgrade', 'improvement', 'development', 'progress', 'evolution'
    ],
    'tech_negative': [
        'bug', 'error', 'failure', 'crash', 'vulnerability', 'security issue',
        'outdated', 'obsolete', 'slow', 'inefficient', 'unreliable', 'unstable',
        'hack', 'breach', 'leak', 'malware', 'virus', 'attack', 'exploit'
    ]
}

class AdvancedSentimentAnalyzer:
    """ê³ ê¸‰ ê°ì„± ë¶„ì„ê¸°"""
    
    def __init__(self, language='en'):
        self.language = language
        self.vader_analyzer = SentimentIntensityAnalyzer()
        
        # í•œêµ­ì–´ ì§€ì›
        if language == 'ko' and KOREAN_SUPPORT:
            self.okt = Okt()
        else:
            self.okt = None
        
        # ê°ì„± ì‚¬ì „ ë¡œë“œ
        self.sentiment_dict = STOCK_SENTIMENT_DICT
        
        # ê°ì„± ì ìˆ˜ ê°€ì¤‘ì¹˜
        self.weights = {
            'vader': 0.4,
            'textblob': 0.3,
            'keyword': 0.3
        }
    
    def analyze_text(self, text: str, context: str = 'general') -> Dict:
        """í…ìŠ¤íŠ¸ ê°ì„± ë¶„ì„"""
        if not text or not text.strip():
            return self._get_neutral_sentiment()
        
        # ì „ì²˜ë¦¬
        cleaned_text = self._preprocess_text(text)
        
        # ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ê°ì„± ë¶„ì„
        vader_score = self._analyze_vader(cleaned_text)
        textblob_score = self._analyze_textblob(cleaned_text)
        keyword_score = self._analyze_keywords(cleaned_text, context)
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        final_score = self._calculate_weighted_score(
            vader_score, textblob_score, keyword_score
        )
        
        return {
            'text': text,
            'cleaned_text': cleaned_text,
            'vader_score': vader_score,
            'textblob_score': textblob_score,
            'keyword_score': keyword_score,
            'final_score': final_score,
            'sentiment': self._classify_sentiment(final_score['compound']),
            'confidence': self._calculate_confidence(vader_score, textblob_score, keyword_score),
            'keywords_found': self._extract_sentiment_keywords(cleaned_text),
            'analysis_timestamp': datetime.now().isoformat()
        }
    
    def _preprocess_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
        # HTML íƒœê·¸ ì œê±°
        text = re.sub(r'<[^>]+>', '', text)
        
        # URL ì œê±°
        text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)
        
        # íŠ¹ìˆ˜ ë¬¸ì ì •ë¦¬
        text = re.sub(r'[^\w\s]', ' ', text)
        
        # ì—°ì†ëœ ê³µë°± ì œê±°
        text = re.sub(r'\s+', ' ', text)
        
        # ì†Œë¬¸ì ë³€í™˜
        text = text.lower().strip()
        
        return text
    
    def _analyze_vader(self, text: str) -> Dict:
        """VADER ê°ì„± ë¶„ì„"""
        try:
            scores = self.vader_analyzer.polarity_scores(text)
            return {
                'compound': scores['compound'],
                'positive': scores['pos'],
                'neutral': scores['neu'],
                'negative': scores['neg']
            }
        except Exception as e:
            print(f"VADER ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {'compound': 0.0, 'positive': 0.0, 'neutral': 1.0, 'negative': 0.0}
    
    def _analyze_textblob(self, text: str) -> Dict:
        """TextBlob ê°ì„± ë¶„ì„"""
        try:
            blob = TextBlob(text)
            polarity = blob.sentiment.polarity
            subjectivity = blob.sentiment.subjectivity
            
            # polarityë¥¼ compound ì ìˆ˜ë¡œ ë³€í™˜
            compound = polarity
            
            return {
                'compound': compound,
                'polarity': polarity,
                'subjectivity': subjectivity,
                'positive': max(0, polarity),
                'negative': max(0, -polarity),
                'neutral': 1 - abs(polarity)
            }
        except Exception as e:
            print(f"TextBlob ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {'compound': 0.0, 'polarity': 0.0, 'subjectivity': 0.5, 'positive': 0.0, 'negative': 0.0, 'neutral': 1.0}
    
    def _analyze_keywords(self, text: str, context: str) -> Dict:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì„± ë¶„ì„"""
        words = text.split()
        positive_count = 0
        negative_count = 0
        total_words = len(words)
        
        if total_words == 0:
            return {'compound': 0.0, 'positive': 0.0, 'negative': 0.0, 'neutral': 1.0}
        
        # ì»¨í…ìŠ¤íŠ¸ë³„ í‚¤ì›Œë“œ ì„ íƒ
        if context == 'stock':
            pos_keywords = self.sentiment_dict['positive'] + self.sentiment_dict['tech_positive']
            neg_keywords = self.sentiment_dict['negative'] + self.sentiment_dict['tech_negative']
        elif context == 'tech':
            pos_keywords = self.sentiment_dict['tech_positive']
            neg_keywords = self.sentiment_dict['tech_negative']
        else:
            pos_keywords = self.sentiment_dict['positive']
            neg_keywords = self.sentiment_dict['negative']
        
        # í‚¤ì›Œë“œ ë§¤ì¹­
        for word in words:
            if word in pos_keywords:
                positive_count += 1
            elif word in neg_keywords:
                negative_count += 1
        
        # ì ìˆ˜ ê³„ì‚°
        pos_ratio = positive_count / total_words
        neg_ratio = negative_count / total_words
        compound = pos_ratio - neg_ratio
        
        return {
            'compound': compound,
            'positive': pos_ratio,
            'negative': neg_ratio,
            'neutral': 1 - pos_ratio - neg_ratio
        }
    
    def _calculate_weighted_score(self, vader: Dict, textblob: Dict, keyword: Dict) -> Dict:
        """ê°€ì¤‘ í‰ê·  ì ìˆ˜ ê³„ì‚°"""
        compound = (
            vader['compound'] * self.weights['vader'] +
            textblob['compound'] * self.weights['textblob'] +
            keyword['compound'] * self.weights['keyword']
        )
        
        positive = (
            vader['positive'] * self.weights['vader'] +
            textblob['positive'] * self.weights['textblob'] +
            keyword['positive'] * self.weights['keyword']
        )
        
        negative = (
            vader['negative'] * self.weights['vader'] +
            textblob['negative'] * self.weights['textblob'] +
            keyword['negative'] * self.weights['keyword']
        )
        
        neutral = 1 - positive - negative
        
        return {
            'compound': compound,
            'positive': positive,
            'negative': negative,
            'neutral': neutral
        }
    
    def _classify_sentiment(self, compound_score: float) -> str:
        """ê°ì„± ë¶„ë¥˜"""
        if compound_score >= 0.05:
            return 'positive'
        elif compound_score <= -0.05:
            return 'negative'
        else:
            return 'neutral'
    
    def _calculate_confidence(self, vader: Dict, textblob: Dict, keyword: Dict) -> float:
        """ì‹ ë¢°ë„ ê³„ì‚°"""
        # ê° ë°©ë²•ì˜ ì¼ì¹˜ë„ ê³„ì‚°
        vader_sentiment = self._classify_sentiment(vader['compound'])
        textblob_sentiment = self._classify_sentiment(textblob['compound'])
        keyword_sentiment = self._classify_sentiment(keyword['compound'])
        
        sentiments = [vader_sentiment, textblob_sentiment, keyword_sentiment]
        most_common = Counter(sentiments).most_common(1)[0][1]
        
        # ì¼ì¹˜í•˜ëŠ” ë°©ë²•ì˜ ë¹„ìœ¨
        confidence = most_common / len(sentiments)
        
        return confidence
    
    def _extract_sentiment_keywords(self, text: str) -> Dict:
        """ê°ì„± í‚¤ì›Œë“œ ì¶”ì¶œ"""
        words = text.split()
        found_keywords = {
            'positive': [],
            'negative': [],
            'tech_positive': [],
            'tech_negative': []
        }
        
        for word in words:
            for category, keywords in self.sentiment_dict.items():
                if word in keywords:
                    found_keywords[category].append(word)
        
        return found_keywords
    
    def _get_neutral_sentiment(self) -> Dict:
        """ì¤‘ë¦½ ê°ì„± ë°˜í™˜"""
        return {
            'text': '',
            'cleaned_text': '',
            'vader_score': {'compound': 0.0, 'positive': 0.0, 'neutral': 1.0, 'negative': 0.0},
            'textblob_score': {'compound': 0.0, 'polarity': 0.0, 'subjectivity': 0.5, 'positive': 0.0, 'negative': 0.0, 'neutral': 1.0},
            'keyword_score': {'compound': 0.0, 'positive': 0.0, 'negative': 0.0, 'neutral': 1.0},
            'final_score': {'compound': 0.0, 'positive': 0.0, 'negative': 0.0, 'neutral': 1.0},
            'sentiment': 'neutral',
            'confidence': 0.0,
            'keywords_found': {'positive': [], 'negative': [], 'tech_positive': [], 'tech_negative': []},
            'analysis_timestamp': datetime.now().isoformat()
        }
    
    def analyze_batch(self, texts: List[str], contexts: List[str] = None) -> List[Dict]:
        """ë°°ì¹˜ ê°ì„± ë¶„ì„"""
        if contexts is None:
            contexts = ['general'] * len(texts)
        
        results = []
        for text, context in zip(texts, contexts):
            result = self.analyze_text(text, context)
            results.append(result)
        
        return results
    
    def get_sentiment_summary(self, results: List[Dict]) -> Dict:
        """ê°ì„± ë¶„ì„ ê²°ê³¼ ìš”ì•½"""
        if not results:
            return {'error': 'No results to summarize'}
        
        sentiments = [r['sentiment'] for r in results]
        sentiment_counts = Counter(sentiments)
        
        total = len(results)
        positive_ratio = sentiment_counts.get('positive', 0) / total
        negative_ratio = sentiment_counts.get('negative', 0) / total
        neutral_ratio = sentiment_counts.get('neutral', 0) / total
        
        # í‰ê·  ì ìˆ˜
        avg_compound = np.mean([r['final_score']['compound'] for r in results])
        avg_confidence = np.mean([r['confidence'] for r in results])
        
        return {
            'total_texts': total,
            'sentiment_distribution': dict(sentiment_counts),
            'positive_ratio': positive_ratio,
            'negative_ratio': negative_ratio,
            'neutral_ratio': neutral_ratio,
            'average_compound_score': avg_compound,
            'average_confidence': avg_confidence,
            'overall_sentiment': self._classify_sentiment(avg_compound)
        }


def main():
    """í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    analyzer = AdvancedSentimentAnalyzer()
    
    # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸
    test_texts = [
        "This AI breakthrough is amazing! The stock price will definitely go up.",
        "The company reported terrible earnings and the stock crashed.",
        "The new machine learning algorithm shows promising results.",
        "Security vulnerability found in the system, investors are concerned.",
        "Neutral news about the technology sector."
    ]
    
    print("ğŸ” ê°ì„± ë¶„ì„ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    for i, text in enumerate(test_texts, 1):
        print(f"\n{i}. í…ìŠ¤íŠ¸: {text}")
        result = analyzer.analyze_text(text, context='stock')
        print(f"   ê°ì„±: {result['sentiment']}")
        print(f"   ì ìˆ˜: {result['final_score']['compound']:.3f}")
        print(f"   ì‹ ë¢°ë„: {result['confidence']:.3f}")
        print(f"   í‚¤ì›Œë“œ: {result['keywords_found']}")
    
    # ë°°ì¹˜ ë¶„ì„
    print("\n" + "=" * 50)
    print("ğŸ“Š ë°°ì¹˜ ë¶„ì„ ê²°ê³¼")
    
    batch_results = analyzer.analyze_batch(test_texts, ['stock'] * len(test_texts))
    summary = analyzer.get_sentiment_summary(batch_results)
    
    print(f"ì´ í…ìŠ¤íŠ¸ ìˆ˜: {summary['total_texts']}")
    print(f"ê°ì„± ë¶„í¬: {summary['sentiment_distribution']}")
    print(f"ê¸ì • ë¹„ìœ¨: {summary['positive_ratio']:.1%}")
    print(f"ë¶€ì • ë¹„ìœ¨: {summary['negative_ratio']:.1%}")
    print(f"ì¤‘ë¦½ ë¹„ìœ¨: {summary['neutral_ratio']:.1%}")
    print(f"í‰ê·  ì ìˆ˜: {summary['average_compound_score']:.3f}")
    print(f"ì „ì²´ ê°ì„±: {summary['overall_sentiment']}")


if __name__ == '__main__':
    main()

